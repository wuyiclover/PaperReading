# PaperReading

#### 语言模型
- Shortformer: Better Language Modeling Using Shorter Inputs
- ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin Information
- Are Pre-trained Convolutions Better than Pre-trained Transformers?
- Pre-training Universal Language Representation
- Syntax-Enhanced Pre-trained Model

#### 小样本
- Leveraging Type Descriptions for Zero-shot Named Entity Recognition and Classification
- Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference
- Few-Shot Question Answering by Pretraining Span Selection
- Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision
- Risk Minimization for Zero-shot Sequence Labeling
- Siamese Neural Networks for One-shot Image Recognition
- Matching Networks for One Shot Learning
- Prototypical networks for few-shot learning
- Induction Networks for Few-Shot Text Classification
- Learning to Bridge Metric Spaces- Few-shot Joint Learning of IntentDetection and Slot Filling
- Neural Snowball for Few-Shot Relation Learning
- Pre-training Text Representations as Meta Learning
- Universal Natural Language Processing with Limited Annotations Try Few-shot Textual Entailment as a Start


#### 文本推理
- Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning
- KACE: Generating Knowledge Aware Contrastive Explanations for Natural Language Inference
- Learning Faithful Representations of Causal Graphs
- Knowledge-Enriched Event Causality Identifification via Latent Structure Induction Networks 
- UnNatural Language Inference
- LearnDA: Learnable Knowledge-Guided Data Augmentation for Event Causality Identification
- Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning
- TIMEDIAL: Temporal Commonsense Reasoning in Dialog
- Data Augmentation with Adversarial Training for Cross-Lingual NLI
- Alignment Rationale for Natural Language Inference
- Search from History and Reason for Future: Two-stage Reasoning on Temporal Knowledge Graphs
- Exploring Logically Dependent Multi-task Learning with Causal Inference
- Dialogue Natural Language Inference
- NILE Natural Language Inference with Faithful Natural Language Explanations
- Generating Negative Commonsense Knowledge
- Uncertain Natural Language Inference
- Braid Weaving Symbolic and Statistical Knowledge into Coherent Logical Explanations

